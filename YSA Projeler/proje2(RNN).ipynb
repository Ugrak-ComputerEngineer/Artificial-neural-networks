{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "proje2(RNN).ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "oUaerPSoROGF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "bf6beeac-a1f1-457a-9b17-8f30f57df66e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527426537762,
          "user_tz": -180,
          "elapsed": 2851,
          "user": {
            "displayName": "Uğur AKDAĞ",
            "photoUrl": "//lh4.googleusercontent.com/-tBciN_Wozpo/AAAAAAAAAAI/AAAAAAAAAa8/DTfqZtvLGLk/s50-c-k-no/photo.jpg",
            "userId": "113511653702105677446"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#!rm anlatamiyorum*\n",
        "!wget https://raw.githubusercontent.com/Ugrak041/Artificial-neural-networks/master/anlatamiyorum.txt\n",
        "!cat anlatamiyorum.txt"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-05-27 13:08:56--  https://raw.githubusercontent.com/Ugrak041/Artificial-neural-networks/master/anlatamiyorum.txt\r\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\r\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 329 [text/plain]\n",
            "Saving to: ‘anlatamiyorum.txt’\n",
            "\n",
            "anlatamiyorum.txt   100%[===================>]     329  --.-KB/s    in 0s      \n",
            "\n",
            "2018-05-27 13:08:56 (27.7 MB/s) - ‘anlatamiyorum.txt’ saved [329/329]\n",
            "\n",
            "ANLATAMİYORUM  \n",
            "Aglasam sesimi duyar misiniz,  \n",
            "Misralarimda; \n",
            "Dokunabilir misiniz, \n",
            "Gozyaslarima, ellerinizle?  \n",
            "Bilmezdim sarkilarin bu kadar guzel, \n",
            "Kelimelerinse kifayetsiz oldugunu \n",
            "Bu derde dusmeden once.  \n",
            "Bir yer var, biliyorum; \n",
            "Her seyi soylemek mumkun; \n",
            "Epeyce yaklasmisim, duyuyorum; \n",
            "Anlatamiyorum.  \n",
            "\n",
            "Orhan VELİ \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ImtDXemNTSKQ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "217b7158-c527-46a1-ecde-3fe60ab6d65e",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527427161677,
          "user_tz": -180,
          "elapsed": 10302,
          "user": {
            "displayName": "Uğur AKDAĞ",
            "photoUrl": "//lh4.googleusercontent.com/-tBciN_Wozpo/AAAAAAAAAAI/AAAAAAAAAa8/DTfqZtvLGLk/s50-c-k-no/photo.jpg",
            "userId": "113511653702105677446"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.utils import np_utils\n",
        "\n",
        "#Read the data, turn it into lower case\n",
        "data = open(\"anlatamiyorum.txt\").read().lower()\n",
        "#This get the set of characters used in the data and sorts them\n",
        "chars = sorted(list(set(data)))\n",
        "#Total number of characters used in the data\n",
        "totalChars = len(data)\n",
        "#Number of unique chars\n",
        "numberOfUniqueChars = len(chars)\n",
        "\n",
        "#This allows for characters to be represented by numbers\n",
        "CharsForids = {char:Id for Id, char in enumerate(chars)}\n",
        "\n",
        "#This is the opposite to the above\n",
        "idsForChars = {Id:char for Id, char in enumerate(chars)}\n",
        "\n",
        "#How many timesteps e.g how many characters we want to process in one go\n",
        "numberOfCharsToLearn = 100\n",
        "\n",
        "#Since our timestep sequence represetns a process for every 100 chars we omit\n",
        "#the first 100 chars so the loop runs a 100 less or there will be index out of\n",
        "#range\n",
        "counter = totalChars - numberOfCharsToLearn\n",
        "\n",
        "#Input data\n",
        "charX = []\n",
        "#output data\n",
        "y = []\n",
        "#This loops through all the characters in the data skipping the first 100\n",
        "for i in range(0, counter, 1):\n",
        "    #This one goes from 0-100 so it gets 100 values starting from 0 and stops\n",
        "    #just before the 100th value\n",
        "    theInputChars = data[i:i+numberOfCharsToLearn]\n",
        "    #With no : you start with 0, and so you get the actual 100th value\n",
        "    #Essentially, the output Chars is the next char in line for those 100 chars\n",
        "    #in X\n",
        "    theOutputChars = data[i + numberOfCharsToLearn]\n",
        "    #Appends every 100 chars ids as a list into X\n",
        "    charX.append([CharsForids[char] for char in theInputChars])\n",
        "    #For every 100 values there is one y value which is the output\n",
        "    y.append(CharsForids[theOutputChars])\n",
        "\n",
        "#Len charX represents how many of those time steps we have\n",
        "#Our features are set to 1 because in the output we are only predicting 1 char\n",
        "#Finally numberOfCharsToLearn is how many character we process\n",
        "X = np.reshape(charX, (len(charX), numberOfCharsToLearn, 1))\n",
        "\n",
        "#This is done for normalization\n",
        "X = X/float(numberOfUniqueChars)\n",
        "\n",
        "#This sets it up for us so we can have a categorical(#feature) output format\n",
        "y = np_utils.to_categorical(y)\n",
        "#print(y)\n",
        "\n",
        "model = Sequential()\n",
        "#Since we know the shape of our Data we can input the timestep and feature data\n",
        "#The number of timestep sequence are dealt with in the fit function\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "#number of features on the output\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "model.fit(X, y, epochs=5, batch_size=75)\n",
        "#model.save_weights(\"Othello.hdf5\")"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "229/229 [==============================] - 2s 11ms/step - loss: 3.3531\n",
            "Epoch 2/5\n",
            "229/229 [==============================] - 1s 6ms/step - loss: 3.2752\n",
            "Epoch 3/5\n",
            "229/229 [==============================] - 1s 6ms/step - loss: 3.1195\n",
            "Epoch 4/5\n",
            "229/229 [==============================] - 1s 6ms/step - loss: 3.0735\n",
            "Epoch 5/5\n",
            "229/229 [==============================] - 1s 6ms/step - loss: 3.0477\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7faad0b3c2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "JkbO2wxjTV_N",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "c9b65d16-64bf-42a1-e685-f34b02f65e7b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1527427190692,
          "user_tz": -180,
          "elapsed": 686,
          "user": {
            "displayName": "Uğur AKDAĞ",
            "photoUrl": "//lh4.googleusercontent.com/-tBciN_Wozpo/AAAAAAAAAAI/AAAAAAAAAa8/DTfqZtvLGLk/s50-c-k-no/photo.jpg",
            "userId": "113511653702105677446"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "#model.load_weights(\"Othello.hdf5\")\n",
        "\n",
        "randomVal = np.random.randint(0, len(charX)-1)\n",
        "randomStart = charX[randomVal]\n",
        "print('sonuc:')\n",
        "for i in range(5):\n",
        "    x = np.reshape(randomStart, (1, len(randomStart), 1))\n",
        "    x = x/float(numberOfUniqueChars)\n",
        "    #print(len(x), len(randomStart))\n",
        "    #print(x)\n",
        "    pred = model.predict(x)\n",
        "    #print(pred)\n",
        "    index = np.argmax(pred)\n",
        "    #print(index)\n",
        "    randomStart.append(index)\n",
        "    randomStart = randomStart[1: len(randomStart)]\n",
        "print(\"\".join([idsForChars[value] for value in randomStart]))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sonuc:\n",
            "\n",
            "aglasam sesimi duyar misiniz,  \n",
            "misralarimda; \n",
            "dokunabilir misiniz, \n",
            "gozyaslarima, ellerinizle     \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}